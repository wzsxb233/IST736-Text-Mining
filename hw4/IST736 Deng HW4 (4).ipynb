{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "import numpy as np\n",
    "train=p.read_csv(\"pubmed_causal_language_use.csv\", delimiter=',')\n",
    "y=train['label'].values\n",
    "X=train['sentence'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1530,) (1530,) (1531,) (1531,)\n",
      "Daily consumption of 3\\\\xa0g of soluble fiber from 70\\\\xa0g\\\\xa0of oats leads to beneficial effects on the lipid parameters, specifically total cholesterol and low-density lipoprotein cholesterol in hypercholesterolemic Asian Indians.\n",
      "1\n",
      "The lack of symptoms and the preoperative EGD findings were not suggestive of this diagnosis in any case.\n",
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   2   3]\n",
      " [651 260 107 512]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# several commonly used vectorizer setting\n",
    "\n",
    "#  unigram boolean vectorizer, set minimum document frequency to 5\n",
    "unigram_bool_vectorizer = CountVectorizer(encoding='latin-1', binary=True, min_df=5, stop_words='english')\n",
    "\n",
    "#  unigram term frequency vectorizer, set minimum document frequency to 5\n",
    "unigram_count_vectorizer = CountVectorizer(encoding='latin-1', binary=False, min_df=5, stop_words='english')\n",
    "\n",
    "#  unigram and bigram term frequency vectorizer, set minimum document frequency to 5\n",
    "gram12_count_vectorizer = CountVectorizer(encoding='latin-1', ngram_range=(1,2), min_df=5, stop_words='english')\n",
    "\n",
    "#  unigram tfidf vectorizer, set minimum document frequency to 5\n",
    "unigram_tfidf_vectorizer = TfidfVectorizer(encoding='latin-1', use_idf=True, min_df=5, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit vocabulary in training documents and transform the training documents into vectors\n",
    "\n",
    "X_vec1=unigram_count_vectorizer.fit_transform(X)\n",
    "X_vec2=unigram_bool_vectorizer.fit_transform(X)\n",
    "X_vec3=unigram_tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, X_train1, X_test1,X_train2, X_test2,X_train3, X_test3,  y_train, y_test = train_test_split(X, X_vec1,X_vec2, X_vec3, y, test_size=0.5, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# initialize the LinearSVC model\n",
    "svm_clf1 = LinearSVC(C=10)\n",
    "svm_clf2 = LinearSVC(C=10)\n",
    "svm_clf3 = LinearSVC(C=10)\n",
    "\n",
    "# use the training data to train the model\n",
    "svm_clf1.fit(X_train1,y_train)\n",
    "svm_clf2.fit(X_train2,y_train)\n",
    "svm_clf3.fit(X_train3,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[532  76  36  61]\n",
      " [ 56 122  15  41]\n",
      " [ 32  32  17  25]\n",
      " [ 73  41  17 355]]\n",
      "[[526  79  34  66]\n",
      " [ 54 123  15  42]\n",
      " [ 30  33  19  24]\n",
      " [ 76  45  16 349]]\n",
      "[[430 108  53 114]\n",
      " [ 29 135  19  51]\n",
      " [ 12  38  28  28]\n",
      " [ 33  39  22 392]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       705\n",
      "           1       0.45      0.52      0.48       234\n",
      "           2       0.20      0.16      0.18       106\n",
      "           3       0.74      0.73      0.73       486\n",
      "\n",
      "    accuracy                           0.67      1531\n",
      "   macro avg       0.54      0.54      0.54      1531\n",
      "weighted avg       0.67      0.67      0.67      1531\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       705\n",
      "           1       0.44      0.53      0.48       234\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.73      0.72      0.72       486\n",
      "\n",
      "    accuracy                           0.66      1531\n",
      "   macro avg       0.54      0.54      0.54      1531\n",
      "weighted avg       0.67      0.66      0.66      1531\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.61      0.71       705\n",
      "           1       0.42      0.58      0.49       234\n",
      "           2       0.23      0.26      0.25       106\n",
      "           3       0.67      0.81      0.73       486\n",
      "\n",
      "    accuracy                           0.64      1531\n",
      "   macro avg       0.54      0.56      0.54      1531\n",
      "weighted avg       0.69      0.64      0.65      1531\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6616590463749183"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred1 = svm_clf1.predict(X_test1)\n",
    "y_pred2 = svm_clf2.predict(X_test1)\n",
    "y_pred3 = svm_clf3.predict(X_test1)\n",
    "cm1=confusion_matrix(y_test, y_pred1, labels=[0,1,2,3])\n",
    "cm2=confusion_matrix(y_test, y_pred2, labels=[0,1,2,3])\n",
    "cm3=confusion_matrix(y_test, y_pred3, labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2','3']\n",
    "print(cm1)\n",
    "print(cm2)\n",
    "print(cm3)\n",
    "print(classification_report(y_test, y_pred1, target_names=target_names))\n",
    "print(classification_report(y_test, y_pred2, target_names=target_names))\n",
    "print(classification_report(y_test, y_pred3, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no relation\n",
      "(1.3603567496937938, 'esophageal')\n",
      "(1.3828492176709677, 'proposed')\n",
      "(1.4035981750920654, 'specifically')\n",
      "(1.4574677980244173, 'meal')\n",
      "(1.4861196936152612, 'bias')\n",
      "(1.4891036645214306, 'obtained')\n",
      "(1.4947479721251886, 'policy')\n",
      "(1.518923578480536, 'superior')\n",
      "(1.535957270336285, 'needed')\n",
      "(1.8571787441180412, 'european')\n",
      "\n",
      "directcausal\n",
      "(1.470894445409777, 'did')\n",
      "(1.4725563125305057, 'resulted')\n",
      "(1.4920430559946503, 'determinants')\n",
      "(1.516579236450756, 'administered')\n",
      "(1.5357332637946086, 'successful')\n",
      "(1.5398324496044509, 'highly')\n",
      "(1.5565175046165693, 'tolerated')\n",
      "(1.5613627551938094, 'effective')\n",
      "(1.6118872847996417, 'contributed')\n",
      "(1.6408811144571323, 'theory')\n",
      "\n",
      "conditionalcausal\n",
      "(0.9524652763524939, 'appeared')\n",
      "(0.9554093287798371, 'improve')\n",
      "(0.959306102786325, 'mg')\n",
      "(0.9854239143058787, 'cad')\n",
      "(1.0066334595324449, 'influence')\n",
      "(1.1826670329504154, 'helpful')\n",
      "(1.2101228921921385, 'mediated')\n",
      "(1.5563965209452932, 'problem')\n",
      "(1.612360197993797, 'useful')\n",
      "(1.81493562101969, 'length')\n",
      "\n",
      "correlational\n",
      "(1.3695227839323258, 'variant')\n",
      "(1.3876060314293976, 'dysfunction')\n",
      "(1.402827182539878, 'correlation')\n",
      "(1.5428152062758809, 'older')\n",
      "(1.568977140109807, 'significant')\n",
      "(1.681106311036619, 'correlated')\n",
      "(1.7483360446114595, 'rygb')\n",
      "(1.7910390861384888, 'predictors')\n",
      "(1.911522104444163, 'predicted')\n",
      "(2.1264830553187273, 'associated')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## interpreting LinearSVC models\n",
    "## http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "\n",
    "## LinearSVC uses a one-vs-all strategy to extend the binary SVM classifier to multi-class problems\n",
    "## for the Kaggle sentiment classification problem, there are five categories 0,1,2,3,4 with 0 as very negative and 4 very positive\n",
    "## LinearSVC builds five binary classifier, \"very negative vs. others\", \"negative vs. others\", \"neutral vs. others\", \"positive vs. others\", \"very positive vs. others\", \n",
    "## and then pick the most confident prediction as the final prediction.\n",
    "\n",
    "## Linear SVC also ranks all features based on their contribution to distinguish the two concepts in each binary classifier\n",
    "## For category \"0\" (very negative), get all features and their weights and sort them in increasing order\n",
    "feature_ranks0 = sorted(zip(svm_clf1.coef_[0], unigram_tfidf_vectorizer.get_feature_names()))\n",
    "feature_ranks1 = sorted(zip(svm_clf1.coef_[1], unigram_tfidf_vectorizer.get_feature_names()))\n",
    "feature_ranks2 = sorted(zip(svm_clf1.coef_[2], unigram_tfidf_vectorizer.get_feature_names()))\n",
    "feature_ranks3 = sorted(zip(svm_clf1.coef_[3], unigram_tfidf_vectorizer.get_feature_names()))\n",
    "\n",
    "## get the 10 features that are best indicators of very negative sentiment (they are at the bottom of the ranked list)\n",
    "norelation10 = feature_ranks0[-10:]\n",
    "directcausal10=feature_ranks1[-10:]\n",
    "conditionalcausal0=feature_ranks2[-10:]\n",
    "correlational10=feature_ranks3[-10:]\n",
    "print(\"no relation\")\n",
    "for i in range(0, len(norelation10)):\n",
    "    print(norelation10[i])\n",
    "print()\n",
    "\n",
    "print(\"directcausal\")\n",
    "for i in range(0, len(directcausal10)):\n",
    "    print(directcausal10[i])\n",
    "print()\n",
    "\n",
    "print(\"conditionalcausal\")\n",
    "for i in range(0, len(conditionalcausal0)):\n",
    "    print(conditionalcausal0[i])\n",
    "print()\n",
    "\n",
    "print(\"correlational\")\n",
    "for i in range(0, len(correlational10)):\n",
    "    print(correlational10[i])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors: 505\n",
      "too related errors: 251\n",
      "poor related errors: 254\n"
     ]
    }
   ],
   "source": [
    "err_cnt1 = 0\n",
    "toorelate1=0\n",
    "poorrelate1=0\n",
    "for i in range(0, len(y_test)):\n",
    "    if(y_test[i]!= y_pred1[i]):\n",
    "        print(X_test[i])\n",
    "        err_cnt1 = err_cnt1+1\n",
    "print(\"errors:\", err_cnt1)\n",
    "for i in range(0, len(y_test)):\n",
    "    if(y_test[i]> y_pred1[i]):\n",
    "        print(X_test[i])\n",
    "        toorelate1 = toorelate1+1\n",
    "print(\"too related errors:\", toorelate1)\n",
    "for i in range(0, len(y_test)):\n",
    "    if(y_test[i]< y_pred1[i]):\n",
    "        print(X_test[i])\n",
    "        poorrelate1 = poorrelate1+1\n",
    "print(\"poor related errors:\", poorrelate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the MNB module\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# initialize the MNB model\n",
    "nb_clf1= MultinomialNB()\n",
    "nb_clf2= MultinomialNB()\n",
    "nb_clf3= MultinomialNB()\n",
    "\n",
    "# use the training data to train the MNB model\n",
    "# feature_log_prob_ stores the conditional probs for all categories\n",
    "# if the labels are strings, the index is in alphabetic order\n",
    "# e.g. 'f' comes before 't' in alphabet, so 'f' is in [0] dimension and 't' in [1]\n",
    "\n",
    "nb_clf1.fit(X_train1,y_train)\n",
    "nb_clf2.fit(X_train2,y_train)\n",
    "nb_clf3.fit(X_train3,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[509  75  23  98]\n",
      " [ 49 121   6  58]\n",
      " [ 31  37  10  28]\n",
      " [ 45  27   4 410]]\n",
      "[[513  67  22 103]\n",
      " [ 49 122   6  57]\n",
      " [ 35  34  12  25]\n",
      " [ 45  27   4 410]]\n",
      "[[543  47   2 113]\n",
      " [ 65  84   1  84]\n",
      " [ 40  25   1  40]\n",
      " [ 41  10   0 435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76       705\n",
      "           1       0.47      0.52      0.49       234\n",
      "           2       0.23      0.09      0.13       106\n",
      "           3       0.69      0.84      0.76       486\n",
      "\n",
      "    accuracy                           0.69      1531\n",
      "   macro avg       0.55      0.54      0.54      1531\n",
      "weighted avg       0.68      0.69      0.68      1531\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76       705\n",
      "           1       0.49      0.52      0.50       234\n",
      "           2       0.27      0.11      0.16       106\n",
      "           3       0.69      0.84      0.76       486\n",
      "\n",
      "    accuracy                           0.69      1531\n",
      "   macro avg       0.56      0.55      0.55      1531\n",
      "weighted avg       0.68      0.69      0.68      1531\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78       705\n",
      "           1       0.51      0.36      0.42       234\n",
      "           2       0.25      0.01      0.02       106\n",
      "           3       0.65      0.90      0.75       486\n",
      "\n",
      "    accuracy                           0.69      1531\n",
      "   macro avg       0.55      0.51      0.49      1531\n",
      "weighted avg       0.66      0.69      0.66      1531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred4 = nb_clf1.predict(X_test1)\n",
    "y_pred5 = nb_clf2.predict(X_test1)\n",
    "y_pred6 = nb_clf3.predict(X_test1)\n",
    "cm4=confusion_matrix(y_test, y_pred4, labels=[0,1,2,3])\n",
    "cm5=confusion_matrix(y_test, y_pred5, labels=[0,1,2,3])\n",
    "cm6=confusion_matrix(y_test, y_pred6, labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2','3']\n",
    "print(cm4)\n",
    "print(cm5)\n",
    "print(cm6)\n",
    "print(classification_report(y_test, y_pred4, target_names=target_names))\n",
    "print(classification_report(y_test, y_pred5, target_names=target_names))\n",
    "print(classification_report(y_test, y_pred6, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no relation\n",
      "(-5.194457226265445, 'results')\n",
      "(-5.141813492780023, 'trial')\n",
      "(-5.021185504991408, 'high')\n",
      "(-5.021185504991408, 'treatment')\n",
      "(-4.99871264913935, 'needed')\n",
      "(-4.816391092345395, 'clinical')\n",
      "(-4.762323871075119, 'risk')\n",
      "(-4.615720396883244, 'study')\n",
      "(-4.55687989686031, 'studies')\n",
      "(-4.051784947803305, 'patients')\n",
      "\n",
      "directcausal\n",
      "(-5.36467714485613, 'women')\n",
      "(-5.310609923585854, 'effect')\n",
      "(-5.310609923585854, 'significantly')\n",
      "(-5.259316629198304, 'effective')\n",
      "(-5.164006449393979, 'cancer')\n",
      "(-5.164006449393979, 'study')\n",
      "(-5.119554686823145, 'weight')\n",
      "(-5.076995072404349, 'treatment')\n",
      "(-4.92284439257709, 'risk')\n",
      "(-4.4264075062632, 'patients')\n",
      "\n",
      "conditionalcausal\n",
      "(-5.69204721843778, 'role')\n",
      "(-5.574264182781397, 'breast')\n",
      "(-5.574264182781397, 'early')\n",
      "(-5.574264182781397, 'effective')\n",
      "(-5.574264182781397, 'reduce')\n",
      "(-5.46890366712357, 'cancer')\n",
      "(-5.373593487319245, 'increase')\n",
      "(-5.286582110329615, 'improve')\n",
      "(-4.635994544188466, 'patients')\n",
      "(-4.513392222096133, 'risk')\n",
      "\n",
      "correlational\n",
      "(-5.083919246014856, 'women')\n",
      "(-5.057250998932695, 'cancer')\n",
      "(-5.005957704545144, 'diabetes')\n",
      "(-4.910647524740819, 'higher')\n",
      "(-4.844689556949022, 'levels')\n",
      "(-4.844689556949022, 'study')\n",
      "(-4.763011525934754, 'increased')\n",
      "(-3.9943567928666637, 'patients')\n",
      "(-3.8585552517076023, 'risk')\n",
      "(-3.7250238590830795, 'associated')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## interpreting LinearSVC models\n",
    "## http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "\n",
    "## LinearSVC uses a one-vs-all strategy to extend the binary SVM classifier to multi-class problems\n",
    "## for the Kaggle sentiment classification problem, there are five categories 0,1,2,3,4 with 0 as very negative and 4 very positive\n",
    "## LinearSVC builds five binary classifier, \"very negative vs. others\", \"negative vs. others\", \"neutral vs. others\", \"positive vs. others\", \"very positive vs. others\", \n",
    "## and then pick the most confident prediction as the final prediction.\n",
    "\n",
    "## Linear SVC also ranks all features based on their contribution to distinguish the two concepts in each binary classifier\n",
    "## For category \"0\" (very negative), get all features and their weights and sort them in increasing order\n",
    "feature_ranks00 = sorted(zip(nb_clf2.coef_[0], unigram_tfidf_vectorizer.get_feature_names()))\n",
    "feature_ranks11 = sorted(zip(nb_clf2.coef_[1], unigram_tfidf_vectorizer.get_feature_names()))\n",
    "feature_ranks22 = sorted(zip(nb_clf2.coef_[2], unigram_tfidf_vectorizer.get_feature_names()))\n",
    "feature_ranks33 = sorted(zip(nb_clf2.coef_[3], unigram_tfidf_vectorizer.get_feature_names()))\n",
    "\n",
    "## get the 10 features that are best indicators of very negative sentiment (they are at the bottom of the ranked list)\n",
    "norelation10B = feature_ranks00[-10:]\n",
    "directcausal10B=feature_ranks11[-10:]\n",
    "conditionalcausal0B=feature_ranks22[-10:]\n",
    "correlational10B=feature_ranks33[-10:]\n",
    "print(\"no relation\")\n",
    "for i in range(0, len(norelation10B)):\n",
    "    print(norelation10B[i])\n",
    "print()\n",
    "\n",
    "print(\"directcausal\")\n",
    "for i in range(0, len(directcausal10B)):\n",
    "    print(directcausal10B[i])\n",
    "print()\n",
    "\n",
    "print(\"conditionalcausal\")\n",
    "for i in range(0, len(conditionalcausal0B)):\n",
    "    print(conditionalcausal0B[i])\n",
    "print()\n",
    "\n",
    "print(\"correlational\")\n",
    "for i in range(0, len(correlational10B)):\n",
    "    print(correlational10B[i])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors: 474\n",
      "too related errors: 194\n",
      "poor related errors: 280\n"
     ]
    }
   ],
   "source": [
    "err_cnt2 = 0\n",
    "toorelate2=0\n",
    "poorrelate2=0\n",
    "for i in range(0, len(y_test)):\n",
    "    if(y_test[i]!= y_pred5[i]):\n",
    "        print(X_test[i])\n",
    "        err_cnt2 = err_cnt2+1\n",
    "print(\"errors:\", err_cnt2)\n",
    "for i in range(0, len(y_test)):\n",
    "    if(y_test[i]> y_pred5[i]):\n",
    "        print(X_test[i])\n",
    "        toorelate2 = toorelate2+1\n",
    "print(\"too related errors:\", toorelate2)\n",
    "for i in range(0, len(y_test)):\n",
    "    if(y_test[i]< y_pred5[i]):\n",
    "        print(X_test[i])\n",
    "        poorrelate2 = poorrelate2+1\n",
    "print(\"poor related errors:\", poorrelate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-ed0d9fbac4d5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-ed0d9fbac4d5>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    git clone -b master https://github.com/charles9n/bert-sklearn\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!git clone -b master https://github.com/charles9n/bert-sklearn\n",
    "!cd bert-sklearn; pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_sklearn import BertClassifier\n",
    "model1 = BertClassifier()         # text/text pair classification\n",
    "print(model1)\n",
    "model2.fit(X_train1, y_train)\n",
    "model2 = BertClassifier()         # text/text pair classification\n",
    "print(model2)\n",
    "model3.fit(X_train2, y_train)\n",
    "model3 = BertClassifier()         # text/text pair classification\n",
    "print(model3)\n",
    "model.fit(X_train3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred7 = model1.predict(X_test1)\n",
    "y_pred8 = model2.predict(X_test1)\n",
    "y_pred9 = model3.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8f4a90dd33f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcm7\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcm8\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcm9\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm7=confusion_matrix(y_test, y_pred7, labels=[0,1,2,3])\n",
    "cm8=confusion_matrix(y_test, y_pred8, labels=[0,1,2,3])\n",
    "cm9=confusion_matrix(y_test, y_pred9, labels=[0,1,2,3])\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2','3']\n",
    "print(cm7)\n",
    "print(cm8)\n",
    "print(cm9)\n",
    "print(classification_report(y_test, y_pred7, target_names=target_names))\n",
    "print(classification_report(y_test, y_pred8, target_names=target_names))\n",
    "print(classification_report(y_test, y_pred9, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
